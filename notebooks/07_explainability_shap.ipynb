{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# 🔍 Advanced Explainability with SHAP for Fraud Detection\n",
        "\n",
        "## 🎯 Overview\n",
        "\n",
        "This notebook provides a comprehensive guide to **SHAP (SHapley Additive exPlanations)** for fraud detection model interpretability. SHAP is the gold standard for explaining machine learning predictions, especially important for regulatory compliance and business transparency.\n",
        "\n",
        "### 🔍 What You'll Learn\n",
        "\n",
        "1. **🧠 SHAP Fundamentals**: Understanding Shapley values and their importance\n",
        "2. **⚡ SHAP Explainers**: TreeExplainer, KernelExplainer, and DeepExplainer\n",
        "3. **📊 Global Explanations**: Understanding model behavior across all predictions\n",
        "4. **🎯 Local Explanations**: Explaining individual fraud predictions\n",
        "5. **📈 Visualization**: Waterfall plots, summary plots, and force plots\n",
        "6. **🏦 Business Applications**: Regulatory compliance and decision support\n",
        "\n",
        "### 🌟 Key Benefits\n",
        "\n",
        "- **⚖️ Regulatory Compliance**: Meet explainability requirements (GDPR, Basel III)\n",
        "- **🎯 Model Debugging**: Identify biases and unexpected patterns\n",
        "- **📊 Feature Insights**: Understand which features drive fraud predictions\n",
        "- **🤝 Stakeholder Communication**: Explain decisions to business users\n",
        "\n",
        "---\n",
        "\n",
        "## 🏗️ SHAP Architecture\n",
        "\n",
        "```\n",
        "🤖 Trained Fraud Model\n",
        "        ↓\n",
        "🔍 SHAP Explainer (Tree/Kernel/Deep)\n",
        "        ↓\n",
        "📊 Shapley Values (Feature Contributions)\n",
        "        ↓\n",
        "📈 Visualizations + 📝 Natural Language Explanations\n",
        "        ↓\n",
        "⚖️ Compliance Reports + 🎯 Business Actions\n",
        "```\n",
        "\n",
        "### 📚 SHAP Theory Overview\n",
        "\n",
        "**Shapley Values** come from cooperative game theory and provide the **only** explanation method that satisfies these important properties:\n",
        "\n",
        "- **🎯 Efficiency**: All feature contributions sum to the prediction difference\n",
        "- **⚖️ Symmetry**: Features with identical impact get identical contributions\n",
        "- **🔄 Dummy**: Features that don't affect the model get zero contribution\n",
        "- **📊 Additivity**: Consistent across different models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add project root to path\n",
        "sys.path.append(os.path.abspath('..'))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "# ML libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# SHAP for explainability\n",
        "try:\n",
        "    import shap\n",
        "    print(\"✅ SHAP imported successfully!\")\n",
        "    shap.initjs()  # Initialize JavaScript for SHAP visualizations\n",
        "except ImportError:\n",
        "    print(\"⚠️ SHAP not found. Install with: pip install shap\")\n",
        "\n",
        "# Configuration\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"🔍 Advanced SHAP Explainability for Fraud Detection\")\n",
        "print(\"=\" * 55)\n",
        "print(\"✅ All libraries imported successfully!\")\n",
        "print(f\"📅 Notebook initialized at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# 🔍 Advanced Explainability with SHAP for Fraud Detection\n",
        "\n",
        "## 🎯 Overview\n",
        "\n",
        "This notebook provides a comprehensive guide to **SHAP (SHapley Additive exPlanations)** for fraud detection model interpretability. SHAP is the gold standard for explaining machine learning predictions, especially important for regulatory compliance and business transparency.\n",
        "\n",
        "### 🔍 What You'll Learn\n",
        "\n",
        "1. **🧠 SHAP Fundamentals**: Understanding Shapley values and their importance\n",
        "2. **⚡ SHAP Explainers**: TreeExplainer, KernelExplainer, and DeepExplainer\n",
        "3. **📊 Global Explanations**: Understanding model behavior across all predictions\n",
        "4. **🎯 Local Explanations**: Explaining individual fraud predictions\n",
        "5. **📈 Visualization**: Waterfall plots, summary plots, and force plots\n",
        "6. **🏦 Business Applications**: Regulatory compliance and decision support\n",
        "\n",
        "### 🌟 Key Benefits\n",
        "\n",
        "- **⚖️ Regulatory Compliance**: Meet explainability requirements (GDPR, Basel III)\n",
        "- **🎯 Model Debugging**: Identify biases and unexpected patterns\n",
        "- **📊 Feature Insights**: Understand which features drive fraud predictions\n",
        "- **🤝 Stakeholder Communication**: Explain decisions to business users\n",
        "\n",
        "---\n",
        "\n",
        "## 🏗️ SHAP Architecture\n",
        "\n",
        "```\n",
        "🤖 Trained Fraud Model\n",
        "        ↓\n",
        "🔍 SHAP Explainer (Tree/Kernel/Deep)\n",
        "        ↓\n",
        "📊 Shapley Values (Feature Contributions)\n",
        "        ↓\n",
        "📈 Visualizations + 📝 Natural Language Explanations\n",
        "        ↓\n",
        "⚖️ Compliance Reports + 🎯 Business Actions\n",
        "```\n",
        "\n",
        "### 📚 SHAP Theory Overview\n",
        "\n",
        "**Shapley Values** come from cooperative game theory and provide the **only** explanation method that satisfies these important properties:\n",
        "\n",
        "- **🎯 Efficiency**: All feature contributions sum to the prediction difference\n",
        "- **⚖️ Symmetry**: Features with identical impact get identical contributions\n",
        "- **🔄 Dummy**: Features that don't affect the model get zero contribution\n",
        "- **📊 Additivity**: Consistent across different models\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
